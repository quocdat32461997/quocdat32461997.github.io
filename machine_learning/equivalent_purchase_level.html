---
layout: default
---
<section>
  <h1 id = "title">Deep Image Clustering - Equivalent Purchase Level </h1>
  <h3 id = "problem_statement">
    This is the challenge/problem by eBay that many similar
    listings may have different prices. This fact poses
    inconvenience to eBay's customers and to me as well when shopping.
    Hence, I want to solve this challenge by developing Deep Clustering algorithm
    to cluster same products together.
  </h3>
  <p>
    <b>Techs used: </b> Python, Keras, Nummpy, Pandas, Matplotlib, Ray - Parallel Processing,
     OpenCV, requests (RESTful API module), AMD GPU
  </p>

  <section id = "challenges">
    <h3>Challenges</h3>
    <p>
      A big challenge of <b>Unsupervised Image Clustering</b> is no pre-trained models
      specified for clustering images. And Unsupervised Image Clustering is difficult
      as natural due to the need of huge dataset to learn representatives of images. Another
      challenge is the big dataset of <b>1 million images and corresponding captions</b>
      (upto 1 TB) given by eBay for training Clustering models.
    </p>
  </section>

  <section id = "inpsect_dadta">
    <h3>Data Inspection</h3>
    <img src="statics/equivalent_purchase_level/data_shape.png"/>
    <br>
    <img src="statics/equivalent_purchase_level/first_look.png"/>
    <p>
      Look at data shape, my team and I received 1002275 listings consisting of images and captions.
      <br><br>
      Rough analysis:
      <ul style = "">
        <li>category: type of listing</li>
        <li>title: name or title of listing. This is significant if clustering listings by text</li>
        <li>subtitle: double that subtitle has all NaN values</li>
        <li>gallery_url / picture_url: urls to images of the listing. Some work need done here to parse and get all images</li>
        <li>attributes: properties of products. Also need parsing into proper formats</li>
        <li>description_in_base64: attributes in html</li>
        <li>index: index</li>
      </ul>
      As a Unsupervised Learning problem, no much statistics could be performed here.
      <img src = "statics/equivalent_purchase_level/category.png"/>
    </p>
  </section>

  <section id = "preprocssing">
    <section id = "why_processing">
      <h3>Why preprocessing?</h3>
      <p>
        In academic projets, datasets (e.g. Titanic, Iris) are preprocessed and cleaned for studnets. However, the proper data is note
        is not the fact in reality. Noise and inconsistent image format (different channels/colors and different size) are always there.
      </p>
    </section>
    <section id = "preprocessing_steps">
      <h3>How to preprocess them?</h3>
      <img src = "statics/equivalent_purchase_level/samples.png"/>
      <p>
        <b> Inconsistent image size - </b> As you can see, no image has the same size (white blank filling).
        Hence, need to resize them into a consistent image size.
        <br>
        <b> Standardizing </b> is another important task to prevent weight explosion.
        Statistically, this is for easy comparision between images, which directly helps gradient descent
        constantly move to minimum point and minimize loss function. Standardizing can be done by steps:
        <img src = "statics/equivalent_purchase_level/standardizing.png"/>
        Standardized images have have a mean of 0 and standard deviation of 1
      </p>
    </section>

  </section>

  <section id="deep_clustering_model">
    <section id = "overview of deep clustering">
      <h3> What is Image Clustering? What are challenges?</h3>
      <p>
        Image Clustering is defined as a problem of classifying/grouping images into similar groups.
        <a href = "https://scikit-learn.org/stable/modules/clustering.html"> Clustering
         algorithms (e.g. K-Means and Hierarchical Clustering)</a> are found
        good in clustering objects based on features. However, features are
        unknown because they are embedded within images. Hence, <a href = "https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5">
        Convolutional Neural Networks (CNN)</a> is well-known for its power in extracing
        image features, which could be fed to Clustering algorithms to cluster images.
      </p>
    </section>

    <section id = "deep_embedding_clustering">
      <h3> Deep Embedding Clustering (DEC) </h3>
      <p>
        DEC is a Deep Learning model built based on the Variational Autoencoder (VAE) and Vania Neural Nets (NN).
        VAE is the symmetrical autoencoder which deep layers are Vanila Neural Nets (Fully Connected Layers).
        Neural Nets are designed based on the network of neurons in humans brain.
        <br>
        More information can be found below:
        <ul>
          <li> <a href = "https://arxiv.org/abs/1511.06335"> Deep Embedding Clustering</a> </li>
          <li> <a href = ""> Variational Autoencoder</a> </li>
          <li> <a href = ""> Neural Networks / Fully Connectd Layers </li>
        </ul>
      </p>
    </section>
  </section>
</section>
