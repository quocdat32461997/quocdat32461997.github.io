---
layout: default
---
<section>
  <h1 id = "title">Deep Image Clustering - Equivalent Purchase Level </h1>
  <h3 id = "problem_statement">
    This is the challenge/problem by eBay that many similar
    listings may have different prices. This fact poses
    inconvenience to eBay's customers and to me as well when shopping.
    Hence, I want to solve this challenge by developing Deep Clustering algorithm
    to cluster same products together.
  </h3>
  <p>
    <b>Techs used: </b> Python, Keras, Nummpy, Pandas, Matplotlib, Ray - Parallel Processing,
     OpenCV, requests (RESTful API module), AMD GPU
  </p>

  <section id = "challenges">
    <h3>Challenges</h3>
    <p>
      A big challenge of <b>Unsupervised Image Clustering</b> is no pre-trained models
      specified for clustering images. And Unsupervised Image Clustering is difficult
      as natural due to the need of huge dataset to learn representatives of images. Another
      challenge is the big dataset of <b>1 million images and corresponding captions</b>
      (upto 1 TB) given by eBay for training Clustering models.
    </p>
  </section>

  <section id = "inpsect_dadta">
    <h3>Data Inspection</h3>
    <img src="statics/equivalent_purchase_level/data_shape.png"/>
    <br>
    <img src="statics/equivalent_purchase_level/first_look.png"/>
    <p>
      Look at data shape, my team and I received 1002275 listings consisting of images and captions.
      <br><br>
      Rough analysis:
      <ul style = "">
        <li>category: type of listing</li>
        <li>title: name or title of listing. This is significant if clustering listings by text</li>
        <li>subtitle: double that subtitle has all NaN values</li>
        <li>gallery_url / picture_url: urls to images of the listing. Some work need done here to parse and get all images</li>
        <li>attributes: properties of products. Also need parsing into proper formats</li>
        <li>description_in_base64: attributes in html</li>
        <li>index: index</li>
      </ul>
      As a Unsupervised Learning problem, no much statistics could be performed here.
      <img src = "statics/equivalent_purchase_level/category.png"/>
    </p>
  </section>

  <section id = "preprocssing">
    <section id = "why_processing">
      <h3>Why preprocessing?</h3>
      <p>
        In academic projets, datasets (e.g. Titanic, Iris) are preprocessed and cleaned for studnets. However, the proper data is note
        is not the fact in reality. Noise and inconsistent image format (different channels/colors and different size) are always there.
      </p>
      <img src = "statics/equivalent_purchase_level/samples.png"/>
      <p>
        <b> Inconsistent image size - </b> As you can see, no image has the same size (white blank filling).
        Hence, need to resize them into a consistent image size.
        <br>
        <b> Standardizing </b> is another important task to prevent weight explosion.
        Statistically, this is for easy comparision between images, which directly helps gradient descent
        constantly move to minimum point and minimize loss function. Standardizing can be done by steps:
        <ul>
          <li>Calculating means of images and Standard Deviation (SD) of images</li>
          <li>Subtract the calculated image means from images</li>
          <li>Finally, divide the above difference by Standard Deviation</li>
          <li>Final results are images standardized to have a mean of 0 and standard deviation of 1</li>
        </ul>
      </p>
    </section>
  </section>
</section>
